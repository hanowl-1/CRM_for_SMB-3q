import { NextRequest, NextResponse } from 'next/server';
import { getSupabase } from '@/lib/database/supabase-client';
import { 
  getKoreaTime, 
  formatKoreaTime 
} from '@/lib/utils/timezone';

/**
 * ì‹œìŠ¤í…œ ì •ë¦¬ ë° ë ˆê±°ì‹œ ì½”ë“œ ì²´í¬ API
 * - ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ìŠ¤ì¼€ì¤„ ì¡ ì •ë¦¬
 * - ì˜¤ë˜ëœ ë¡œê·¸ ë°ì´í„° ì •ë¦¬
 * - ì¤‘ë³µëœ ì›Œí¬í”Œë¡œìš° ì²´í¬
 * - ë ˆê±°ì‹œ ì„¤ì • ì‹ë³„
 */
export async function GET(request: NextRequest) {
  try {
    const client = getSupabase();
    const now = getKoreaTime();
    const cleanupReport = [];
    
    console.log(`ğŸ§¹ ì‹œìŠ¤í…œ ì •ë¦¬ ì²´í¬ ì‹œì‘: ${formatKoreaTime(now)}`);
    
    // 1. ì˜¤ë˜ëœ ì™„ë£Œ/ì‹¤íŒ¨ ìŠ¤ì¼€ì¤„ ì¡ ì •ë¦¬ (30ì¼ ì´ìƒ)
    const thirtyDaysAgo = new Date(now.getTime() - 30 * 24 * 60 * 60 * 1000);
    
    const { data: oldJobs, error: oldJobsError } = await client
      .from('scheduled_jobs')
      .select('id, status, created_at, workflow_data')
      .in('status', ['completed', 'failed'])
      .lt('created_at', thirtyDaysAgo.toISOString());
    
    if (!oldJobsError && oldJobs && oldJobs.length > 0) {
      cleanupReport.push({
        category: 'old_jobs',
        count: oldJobs.length,
        action: 'delete_recommended',
        description: `30ì¼ ì´ìƒ ëœ ì™„ë£Œ/ì‹¤íŒ¨ ìŠ¤ì¼€ì¤„ ì¡ ${oldJobs.length}ê°œ ë°œê²¬`,
        items: oldJobs.slice(0, 5).map(job => ({
          id: job.id,
          status: job.status,
          created_at: job.created_at,
          workflow_name: job.workflow_data?.name || 'Unknown'
        }))
      });
    }
    
    // 2. ì¤‘ë³µëœ pending ìŠ¤ì¼€ì¤„ ì¡ ì²´í¬
    const { data: pendingJobs } = await client
      .from('scheduled_jobs')
      .select('workflow_id, scheduled_time, id, workflow_data')
      .eq('status', 'pending')
      .order('created_at', { ascending: false });
    
    const duplicateGroups = {};
    pendingJobs?.forEach(job => {
      const key = `${job.workflow_id}_${job.scheduled_time}`;
      if (!duplicateGroups[key]) {
        duplicateGroups[key] = [];
      }
      duplicateGroups[key].push(job);
    });
    
    const duplicates = Object.values(duplicateGroups).filter((group: any) => group.length > 1);
    if (duplicates.length > 0) {
      cleanupReport.push({
        category: 'duplicate_jobs',
        count: duplicates.length,
        action: 'cleanup_required',
        description: `ì¤‘ë³µëœ ìŠ¤ì¼€ì¤„ ì¡ ê·¸ë£¹ ${duplicates.length}ê°œ ë°œê²¬`,
        items: duplicates.slice(0, 3).map((group: any) => ({
          workflow_id: group[0].workflow_id,
          workflow_name: group[0].workflow_data?.name || 'Unknown',
          scheduled_time: group[0].scheduled_time,
          duplicate_count: group.length,
          job_ids: group.map((j: any) => j.id)
        }))
      });
    }
    
    // 3. ë¹„í™œì„± ì›Œí¬í”Œë¡œìš°ì˜ ìŠ¤ì¼€ì¤„ ì¡ ì²´í¬
    const { data: workflows } = await client
      .from('workflows')
      .select('id, name, status');
    
    const activeWorkflowIds = workflows?.filter(w => w.status === 'active').map(w => w.id) || [];
    const inactiveWorkflowIds = workflows?.filter(w => w.status !== 'active').map(w => w.id) || [];
    
    const { data: orphanJobs } = await client
      .from('scheduled_jobs')
      .select('id, workflow_id, workflow_data, status, scheduled_time')
      .eq('status', 'pending')
      .in('workflow_id', inactiveWorkflowIds);
    
    if (orphanJobs && orphanJobs.length > 0) {
      cleanupReport.push({
        category: 'orphan_jobs',
        count: orphanJobs.length,
        action: 'cleanup_required',
        description: `ë¹„í™œì„± ì›Œí¬í”Œë¡œìš°ì˜ ìŠ¤ì¼€ì¤„ ì¡ ${orphanJobs.length}ê°œ ë°œê²¬`,
        items: orphanJobs.slice(0, 5).map(job => ({
          id: job.id,
          workflow_id: job.workflow_id,
          workflow_name: job.workflow_data?.name || 'Unknown',
          scheduled_time: job.scheduled_time
        }))
      });
    }
    
    // 4. ë ˆê±°ì‹œ ì„¤ì • ì²´í¬ (schedule_settings vs schedule_config)
    const { data: legacyWorkflows } = await client
      .from('workflows')
      .select('id, name, schedule_settings, schedule_config')
      .not('schedule_settings', 'is', null);
    
    const needsMigration = legacyWorkflows?.filter(w => 
      w.schedule_settings && !w.schedule_config
    ) || [];
    
    if (needsMigration.length > 0) {
      cleanupReport.push({
        category: 'legacy_config',
        count: needsMigration.length,
        action: 'migration_required',
        description: `ë ˆê±°ì‹œ schedule_settingsë¥¼ ì‚¬ìš©í•˜ëŠ” ì›Œí¬í”Œë¡œìš° ${needsMigration.length}ê°œ ë°œê²¬`,
        items: needsMigration.slice(0, 5).map(w => ({
          id: w.id,
          name: w.name,
          has_schedule_settings: !!w.schedule_settings,
          has_schedule_config: !!w.schedule_config
        }))
      });
    }
    
    // 5. ì‹œìŠ¤í…œ í†µê³„
    const systemStats = {
      total_workflows: workflows?.length || 0,
      active_workflows: activeWorkflowIds.length,
      total_scheduled_jobs: pendingJobs?.length || 0,
      cleanup_candidates: cleanupReport.reduce((sum, item) => sum + item.count, 0)
    };
    
    // 6. ê¶Œì¥ ì •ë¦¬ ì‘ì—…
    const recommendations = [];
    
    if (cleanupReport.some(item => item.category === 'old_jobs')) {
      recommendations.push({
        priority: 'medium',
        action: 'DELETE FROM scheduled_jobs WHERE status IN (\'completed\', \'failed\') AND created_at < NOW() - INTERVAL \'30 days\'',
        description: '30ì¼ ì´ìƒ ëœ ì™„ë£Œ/ì‹¤íŒ¨ ìŠ¤ì¼€ì¤„ ì¡ ì‚­ì œ'
      });
    }
    
    if (cleanupReport.some(item => item.category === 'duplicate_jobs')) {
      recommendations.push({
        priority: 'high',
        action: 'manual_review_required',
        description: 'ì¤‘ë³µëœ ìŠ¤ì¼€ì¤„ ì¡ ìˆ˜ë™ ê²€í†  ë° ì •ë¦¬ í•„ìš”'
      });
    }
    
    if (cleanupReport.some(item => item.category === 'orphan_jobs')) {
      recommendations.push({
        priority: 'high',
        action: 'DELETE FROM scheduled_jobs WHERE workflow_id IN (SELECT id FROM workflows WHERE status != \'active\')',
        description: 'ë¹„í™œì„± ì›Œí¬í”Œë¡œìš°ì˜ ìŠ¤ì¼€ì¤„ ì¡ ì •ë¦¬'
      });
    }
    
    if (cleanupReport.some(item => item.category === 'legacy_config')) {
      recommendations.push({
        priority: 'low',
        action: 'migrate_schedule_settings_to_schedule_config',
        description: 'schedule_settingsë¥¼ schedule_configë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜'
      });
    }
    
    console.log(`âœ… ì‹œìŠ¤í…œ ì •ë¦¬ ì²´í¬ ì™„ë£Œ: ${cleanupReport.length}ê°œ ì¹´í…Œê³ ë¦¬, ${systemStats.cleanup_candidates}ê°œ ì •ë¦¬ ëŒ€ìƒ`);
    
    return NextResponse.json({
      success: true,
      data: {
        check_time: formatKoreaTime(now),
        system_stats: systemStats,
        cleanup_report: cleanupReport,
        recommendations,
        summary: {
          total_issues: cleanupReport.length,
          total_items: systemStats.cleanup_candidates,
          critical_issues: cleanupReport.filter(item => 
            ['duplicate_jobs', 'orphan_jobs'].includes(item.category)
          ).length
        }
      },
      message: cleanupReport.length > 0 
        ? `${cleanupReport.length}ê°œ ì¹´í…Œê³ ë¦¬ì—ì„œ ì •ë¦¬ê°€ í•„ìš”í•œ í•­ëª©ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.`
        : 'ì‹œìŠ¤í…œì´ ê¹”ë”í•œ ìƒíƒœì…ë‹ˆë‹¤.'
    });
    
  } catch (error) {
    console.error('âŒ ì‹œìŠ¤í…œ ì •ë¦¬ ì²´í¬ ì‹¤íŒ¨:', error);
    return NextResponse.json({
      success: false,
      message: 'ì‹œìŠ¤í…œ ì •ë¦¬ ì²´í¬ ì‹¤íŒ¨: ' + (error instanceof Error ? error.message : String(error))
    }, { status: 500 });
  }
}

/**
 * ì‹¤ì œ ì •ë¦¬ ì‘ì—… ì‹¤í–‰ (POST)
 */
export async function POST(request: NextRequest) {
  try {
    const now = getKoreaTime();
    console.log(`\nğŸ§¹ === ì‹œìŠ¤í…œ ì •ë¦¬ ì‹œì‘ (${formatKoreaTime(now)}) ===`);
    
    // 1. 5ë¶„ ì´ìƒ running ìƒíƒœì¸ ì‘ì—…ë“¤ ì¡°íšŒ
    const { data: stuckJobs, error: queryError } = await getSupabase()
      .from('scheduled_jobs')
      .select('*')
      .eq('status', 'running');
    
    if (queryError) {
      throw queryError;
    }
    
    console.log(`ğŸ“‹ running ìƒíƒœ ì‘ì—… ${stuckJobs?.length || 0}ê°œ ë°œê²¬`);
    
    let recoveredCount = 0;
    const recoveredJobs = [];
    
    if (stuckJobs && stuckJobs.length > 0) {
      for (const job of stuckJobs) {
        console.log(`\n--- ì‘ì—… ë¶„ì„: ${job.id} ---`);
        console.log(`ğŸ“‹ ì›Œí¬í”Œë¡œìš°: ${job.workflow_data?.name || 'Unknown'}`);
        console.log(`ğŸ“‹ ì˜ˆì •ì‹œê°„: ${job.scheduled_time}`);
        console.log(`ğŸ“‹ ì‹¤í–‰ì‹œê°„: ${job.executed_at || 'null'}`);
        console.log(`ğŸ“‹ ìƒì„±ì‹œê°„: ${job.created_at}`);
        
        const executedAt = job.executed_at ? new Date(job.executed_at) : null;
        let shouldRecover = false;
        let reason = '';
        
        if (executedAt) {
          // ğŸ”¥ íƒ€ì„ì¡´ ì²˜ë¦¬ ê°•í™”: executed_atì´ í•œêµ­ ì‹œê°„ì¸ì§€ UTCì¸ì§€ í™•ì¸
          let executedTimeKST: Date;
          
          if (job.executed_at.includes('+09:00') || job.executed_at.includes('+0900')) {
            // í•œêµ­ íƒ€ì„ì¡´ì´ í¬í•¨ëœ ê²½ìš°: ì´ë¯¸ í•œêµ­ ì‹œê°„ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            executedTimeKST = new Date(job.executed_at);
            console.log(`ğŸ“… í•œêµ­ ì‹œê°„ executed_at: ${job.executed_at} â†’ ${executedTimeKST.toISOString()}`);
          } else {
            // íƒ€ì„ì¡´ì´ ì—†ê±°ë‚˜ UTCì¸ ê²½ìš°: í•œêµ­ ì‹œê°„ìœ¼ë¡œ ë³€í™˜
            executedTimeKST = new Date(executedAt.getTime() + 9 * 60 * 60 * 1000);
            console.log(`ğŸ“… UTCâ†’KST ë³€í™˜: ${job.executed_at} â†’ ${executedTimeKST.toISOString()}`);
          }
          
          const runningMinutes = (now.getTime() - executedTimeKST.getTime()) / (1000 * 60);
          console.log(`ğŸ“Š ì‹¤í–‰ ì‹œê°„ ê³„ì‚°:`);
          console.log(`   - í˜„ì¬ ì‹œê°„: ${formatKoreaTime(now)} (${now.getTime()})`);
          console.log(`   - ì‹¤í–‰ ì‹œê°„: ${formatKoreaTime(executedTimeKST)} (${executedTimeKST.getTime()})`);
          console.log(`   - ì°¨ì´: ${runningMinutes.toFixed(1)}ë¶„`);
          
          if (runningMinutes > 2) { // 2ë¶„ ì´ìƒ ì‹¤í–‰ ì¤‘ì´ë©´ ë³µêµ¬
            shouldRecover = true;
            reason = `${runningMinutes.toFixed(1)}ë¶„ ë™ì•ˆ ì‹¤í–‰ ì¤‘ (íƒ€ì„ì•„ì›ƒ)`;
          }
        } else {
          // executed_atì´ ì—†ëŠ” running ìƒíƒœëŠ” ë¹„ì •ìƒ
          shouldRecover = true;
          reason = 'executed_at ëˆ„ë½ëœ ë¹„ì •ìƒ running ìƒíƒœ';
        }
        
        if (shouldRecover) {
          console.log(`ğŸ”§ ë³µêµ¬ ì‹œì‘: ${reason}`);
          
          const { error: updateError } = await getSupabase()
            .from('scheduled_jobs')
            .update({
              status: 'failed',
              error_message: `ì‹œìŠ¤í…œ ì •ë¦¬ë¡œ ë³µêµ¬: ${reason}`,
              failed_at: formatKoreaTime(now, 'yyyy-MM-dd HH:mm:ss'),
              updated_at: formatKoreaTime(now, 'yyyy-MM-dd HH:mm:ss')
            })
            .eq('id', job.id);
          
          if (updateError) {
            console.error(`âŒ ì‘ì—… ${job.id} ë³µêµ¬ ì‹¤íŒ¨:`, updateError);
          } else {
            console.log(`âœ… ì‘ì—… ${job.id} ë³µêµ¬ ì™„ë£Œ`);
            recoveredCount++;
            recoveredJobs.push({
              id: job.id,
              workflow_name: job.workflow_data?.name || 'Unknown',
              reason: reason
            });
          }
        } else {
          console.log(`âœ… ì‘ì—… ${job.id}: ì •ìƒ ìƒíƒœ (ë³µêµ¬ ë¶ˆí•„ìš”)`);
        }
      }
    }
    
    // 2. ì˜¤ë˜ëœ pending ì‘ì—…ë“¤ë„ ì •ë¦¬ (24ì‹œê°„ ì´ìƒ ëœ ê²ƒë“¤)
    console.log(`\nğŸ§¹ === ì˜¤ë˜ëœ pending ì‘ì—… ì •ë¦¬ ===`);
    const dayAgo = new Date(now.getTime() - 24 * 60 * 60 * 1000);
    
    const { data: oldPendingJobs, error: oldPendingError } = await getSupabase()
      .from('scheduled_jobs')
      .select('*')
      .eq('status', 'pending')
      .lt('created_at', dayAgo.toISOString());
    
    console.log(`ğŸ“‹ 24ì‹œê°„ ì´ìƒ ëœ pending ì‘ì—… ${oldPendingJobs?.length || 0}ê°œ ë°œê²¬`);
    
    let cleanedOldCount = 0;
    if (oldPendingJobs && oldPendingJobs.length > 0) {
      const { error: cleanupError } = await getSupabase()
        .from('scheduled_jobs')
        .update({
          status: 'failed',
          error_message: '24ì‹œê°„ ì´ìƒ ëœ ì˜¤ë˜ëœ pending ì‘ì—… ìë™ ì •ë¦¬',
          failed_at: formatKoreaTime(now, 'yyyy-MM-dd HH:mm:ss'),
          updated_at: formatKoreaTime(now, 'yyyy-MM-dd HH:mm:ss')
        })
        .eq('status', 'pending')
        .lt('created_at', dayAgo.toISOString());
      
      if (cleanupError) {
        console.error('âŒ ì˜¤ë˜ëœ pending ì‘ì—… ì •ë¦¬ ì‹¤íŒ¨:', cleanupError);
      } else {
        cleanedOldCount = oldPendingJobs.length;
        console.log(`âœ… ì˜¤ë˜ëœ pending ì‘ì—… ${cleanedOldCount}ê°œ ì •ë¦¬ ì™„ë£Œ`);
      }
    }
    
    console.log(`\nğŸ¯ ì •ë¦¬ ì™„ë£Œ:`);
    console.log(`   - ë©ˆì¶˜ ì‘ì—… ë³µêµ¬: ${recoveredCount}ê°œ`);
    console.log(`   - ì˜¤ë˜ëœ ì‘ì—… ì •ë¦¬: ${cleanedOldCount}ê°œ`);
    
    return NextResponse.json({
      success: true,
      data: {
        recovered_stuck_jobs: recoveredCount,
        cleaned_old_jobs: cleanedOldCount,
        recovered_jobs: recoveredJobs,
        timestamp: formatKoreaTime(now)
      },
      message: `ì‹œìŠ¤í…œ ì •ë¦¬ ì™„ë£Œ: ${recoveredCount}ê°œ ë³µêµ¬, ${cleanedOldCount}ê°œ ì •ë¦¬`
    });
    
  } catch (error) {
    console.error('âŒ ì‹œìŠ¤í…œ ì •ë¦¬ ì‹¤íŒ¨:', error);
    return NextResponse.json({
      success: false,
      message: 'ì‹œìŠ¤í…œ ì •ë¦¬ ì‹¤íŒ¨: ' + (error instanceof Error ? error.message : String(error))
    }, { status: 500 });
  }
} 